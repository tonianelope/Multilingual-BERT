{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from fastai.basic_train import Learner\n",
    "from ner_data import DEV, TEST, TRAIN, get_data_bunch\n",
    "from optimizer import BertAdam\n",
    "from learner import BertForNER, ner_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download the conll-2003 dataset\n",
    "for example from https://github.com/Nidhi-K/Natural-Language-Processing-Projects/tree/master/Sequential%20CRF%20for%20NER/data\n",
    "</br>(note: english test set is blind)\n",
    "Full english dataset: https://github.com/kyzhouhzau/BERT-NER/tree/master/NERdata\n",
    "\n",
    "and save it to DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('./data/conll-2003/eng')\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CSV_PATH = Path('./data/conll-2003/csv')\n",
    "CSV_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_BUNCH_PATH = Path('./data/conll-2003/data_bunch')\n",
    "DATA_BUNCH_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ENG = {\n",
    "    TRAIN: 'train.txt',\n",
    "    DEV: 'dev.txt',\n",
    "    TEST: 'test.txt'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! svn co 'https://github.com/Nidhi-K/Natural-Language-Processing-Projects/trunk/Sequential CRF for NER/data/' {DATA_PATH}\n",
    "# ! svn co 'https://github.com/kyzhouhzau/BERT-NER/trunk/NERdata/' {DATA_PATH} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = [DATA_PATH/file for file in [TRAIN, DEV, TEST]]\n",
    "# conll_to_csv(CSV_PATH,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 1703.44it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1251.02it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, 'O': 3, 'B-PER': 4, 'I-PER': 5, 'B-ORG': 6, 'I-ORG': 7, 'B-LOC': 8, 'I-LOC': 9, 'B-MISC': 10, 'I-MISC': 11}\n",
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, 'O': 3, 'B-PER': 4, 'I-PER': 5, 'B-ORG': 6, 'I-ORG': 7, 'B-LOC': 8, 'I-LOC': 9, 'B-MISC': 10, 'I-MISC': 11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 10/10 [00:00<00:00, 1905.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, 'O': 3, 'B-PER': 4, 'I-PER': 5, 'B-ORG': 6, 'I-ORG': 7, 'B-LOC': 8, 'I-LOC': 9, 'B-MISC': 10, 'I-MISC': 11}\n",
      "50\n",
      "10\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = get_data_bunch(DATA_BUNCH_PATH, ENG, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForNER.from_pretrained('bert-base-uncased', num_labels=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, model, BertAdam, loss_func=ner_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1214.8503, grad_fn=<SumBackward0>)\n",
      "tensor(1211.9034, grad_fn=<SumBackward0>)\n",
      "tensor(1218.9008, grad_fn=<SumBackward0>)\n",
      "tensor(1194.9626, grad_fn=<SumBackward0>)\n",
      "tensor(1202.4504, grad_fn=<SumBackward0>)\n",
      "tensor(1214.4149, grad_fn=<SumBackward0>)\n",
      "tensor(1176.1028, grad_fn=<SumBackward0>)\n",
      "tensor(1223.6204, grad_fn=<SumBackward0>)\n",
      "tensor(1142.3104, grad_fn=<SumBackward0>)\n",
      "tensor(1177.3257, grad_fn=<SumBackward0>)\n",
      "tensor(1127.7219, grad_fn=<SumBackward0>)\n",
      "tensor(1112.7767, grad_fn=<SumBackward0>)\n",
      "tensor(1099.4880, grad_fn=<SumBackward0>)\n",
      "tensor(1038.4785, grad_fn=<SumBackward0>)\n",
      "tensor(1072.7346, grad_fn=<SumBackward0>)\n",
      "tensor(1021.4463, grad_fn=<SumBackward0>)\n",
      "tensor(939.7308, grad_fn=<SumBackward0>)\n",
      "tensor(984.4964, grad_fn=<SumBackward0>)\n",
      "tensor(815.6038, grad_fn=<SumBackward0>)\n",
      "tensor(781.8853, grad_fn=<SumBackward0>)\n",
      "tensor(735.1388, grad_fn=<SumBackward0>)\n",
      "tensor(562.3269, grad_fn=<SumBackward0>)\n",
      "tensor(419.0259, grad_fn=<SumBackward0>)\n",
      "tensor(230.8863, grad_fn=<SumBackward0>)\n",
      "tensor(167.8319, grad_fn=<SumBackward0>)\n",
      "tensor(145.2310, grad_fn=<SumBackward0>)\n",
      "tensor(85.0530, grad_fn=<SumBackward0>)\n",
      "tensor(160.3519, grad_fn=<SumBackward0>)\n",
      "tensor(111.5423, grad_fn=<SumBackward0>)\n",
      "tensor(121.7482, grad_fn=<SumBackward0>)\n",
      "tensor(77.5275, grad_fn=<SumBackward0>)\n",
      "tensor(51.3407, grad_fn=<SumBackward0>)\n",
      "tensor(58.9677, grad_fn=<SumBackward0>)\n",
      "tensor(49.1343, grad_fn=<SumBackward0>)\n",
      "tensor(17.4991, grad_fn=<SumBackward0>)\n",
      "tensor(46.6307, grad_fn=<SumBackward0>)\n",
      "tensor(6.5369, grad_fn=<SumBackward0>)\n",
      "tensor(5.1088, grad_fn=<SumBackward0>)\n",
      "tensor(2.0783, grad_fn=<SumBackward0>)\n",
      "tensor(90.4410, grad_fn=<SumBackward0>)\n",
      "tensor(29.0348, grad_fn=<SumBackward0>)\n",
      "tensor(8.1912, grad_fn=<SumBackward0>)\n",
      "tensor(20.3483, grad_fn=<SumBackward0>)\n",
      "tensor(1330.5591, grad_fn=<SumBackward0>)\n",
      "tensor(40.5044, grad_fn=<SumBackward0>)\n",
      "tensor(2132.8755, grad_fn=<SumBackward0>)\n",
      "tensor(376.8530, grad_fn=<SumBackward0>)\n",
      "tensor(4016.3301, grad_fn=<SumBackward0>)\n",
      "tensor(757.2609, grad_fn=<SumBackward0>)\n",
      "tensor(117.4441, grad_fn=<SumBackward0>)\n",
      "tensor(251.0518, grad_fn=<SumBackward0>)\n",
      "tensor(1433.3665, grad_fn=<SumBackward0>)\n",
      "tensor(1357.5385, grad_fn=<SumBackward0>)\n",
      "tensor(99.4208, grad_fn=<SumBackward0>)\n",
      "tensor(5773.3799, grad_fn=<SumBackward0>)\n",
      "tensor(1787.4548, grad_fn=<SumBackward0>)\n",
      "tensor(209.2681, grad_fn=<SumBackward0>)\n",
      "tensor(268.3384, grad_fn=<SumBackward0>)\n",
      "tensor(97.0460, grad_fn=<SumBackward0>)\n",
      "tensor(281.9483, grad_fn=<SumBackward0>)\n",
      "tensor(699.2404, grad_fn=<SumBackward0>)\n",
      "tensor(153.9874, grad_fn=<SumBackward0>)\n",
      "tensor(462.2316, grad_fn=<SumBackward0>)\n",
      "tensor(112.4229, grad_fn=<SumBackward0>)\n",
      "tensor(2713.3938, grad_fn=<SumBackward0>)\n",
      "tensor(3163.8618, grad_fn=<SumBackward0>)\n",
      "tensor(1164.2853, grad_fn=<SumBackward0>)\n",
      "tensor(440.7934, grad_fn=<SumBackward0>)\n",
      "tensor(226.8384, grad_fn=<SumBackward0>)\n",
      "tensor(1115.9557, grad_fn=<SumBackward0>)\n",
      "tensor(478.8872, grad_fn=<SumBackward0>)\n",
      "tensor(395.8755, grad_fn=<SumBackward0>)\n",
      "tensor(2692.1904, grad_fn=<SumBackward0>)\n",
      "tensor(327.6129, grad_fn=<SumBackward0>)\n",
      "tensor(499.9594, grad_fn=<SumBackward0>)\n",
      "tensor(6512.1455, grad_fn=<SumBackward0>)\n",
      "tensor(960.1111, grad_fn=<SumBackward0>)\n",
      "tensor(inf, grad_fn=<SumBackward0>)\n",
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1,0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fastaiv1)",
   "language": "python",
   "name": "fastaiv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
